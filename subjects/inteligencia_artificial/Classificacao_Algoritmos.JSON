{
  "subject": "Algoritmos de Aprendizado de Máquina",
  "subtopicsLabel": "Categorias",
  "topics": {
    "name": "Técnicas de Aprendizado de Máquina",
    "values": [
      {
        "name": "Classificação",
        "key": "CLASS",
        "comment": "Algoritmos que predizem categorias ou classes discretas, atribuindo rótulos a instâncias baseado em características.",
        "subtopics": [
          {
            "name": "Regressão Logística",
            "key": "LOG_REG",
            "comment": "Classificador probabilístico que estima a probabilidade de uma instância pertencer a uma classe usando a função logística."
          },
          {
            "name": "Naive Bayes",
            "key": "NAIVE_BAYES",
            "comment": "Classificador baseado no Teorema de Bayes que assume independência condicional entre as características."
          }
        ]
      },
      {
        "name": "Classificação/Regressão",
        "key": "CLASS_REGR",
        "comment": "Algoritmos versáteis que podem ser configurados para resolver tanto problemas de classificação quanto de regressão.",
        "subtopics": [
          {
            "name": "Decision Trees",
            "key": "DECISION_TREES",
            "comment": "Árvores de Decisão - Modelos versáteis que podem ser usados tanto para classificação quanto para regressão, criando uma estrutura de árvore baseada em regras."
          },
          {
            "name": "Gradient Boosting",
            "key": "GRAD_BOOST",
            "comment": "Família de algoritmos ensemble (XGBoost, LightGBM, CatBoost) que combinam múltiplos modelos fracos sequencialmente para classificação ou regressão."
          },
          {
            "name": "KNN",
            "key": "KNN",
            "comment": "k-Nearest Neighbors - Algoritmo versátil que pode ser usado tanto para classificação (votação majoritária) quanto para regressão (média dos valores)."
          },
          {
            "name": "Redes Neurais",
            "key": "NEURAL_NETS",
            "comment": "Arquiteturas flexíveis que podem ser configuradas para tarefas de classificação (softmax) ou regressão (saída linear) através de sua camada de saída."
          },
          {
            "name": "Random Forest",
            "key": "RANDOM_FOREST",
            "comment": "Ensemble de árvores de decisão que pode realizar tanto classificação (votação) quanto regressão (média das previsões)."
          },
          {
            "name": "SVM",
            "key": "SVM",
            "comment": "Support Vector Machines - Podem ser usadas para classificação (SVC) ou regressão (SVR) através de diferentes funções de kernel e configurações."
          }
        ]
      },
      {
        "name": "Regressão",
        "key": "REGR",
        "comment": "Algoritmos que predizem valores contínuos ou numéricos, estabelecendo relações entre variáveis independentes e dependentes.",
        "subtopics": [
          {
            "name": "Elastic Net",
            "key": "ELASTIC_NET",
            "comment": "Combinação das penalizações L1 (Lasso) e L2 (Ridge) para regressão linear regularizada, útil quando há alta correlação entre características."
          },
          {
            "name": "Lasso",
            "key": "LASSO",
            "comment": "Regressão linear com regularização L1, que realiza seleção de características ao zerar coeficientes irrelevantes."
          },
          {
            "name": "Ridge",
            "key": "RIDGE",
            "comment": "Regressão linear com regularização L2, que reduz a magnitude dos coeficientes para lidar com multicolinearidade."
          },
          {
            "name": "Regression Trees",
            "key": "REG_TREES",
            "comment": "Árvores de decisão otimizadas especificamente para tarefas de regressão, usando valores médios nas folhas."
          },
          {
            "name": "Regressão Linear",
            "key": "LIN_REG",
            "comment": "Modelo estatístico fundamental que estabelece uma relação linear entre variáveis independentes e uma variável dependente contínua."
          }
        ]
      },
      {
        "name": "Clustering",
        "key": "CLUST",
        "comment": "Algoritmos não supervisionados que agrupam dados similares em clusters, descobrindo estruturas ocultas nos dados.",
        "subtopics": [
          {
            "name": "DBSCAN",
            "key": "DBSCAN",
            "comment": "Density-Based Spatial Clustering - Agrupa pontos baseado em densidade local, identificando clusters de formas arbitrárias e detectando outliers."
          },
          {
            "name": "Gaussian Mixture Models (GMM)",
            "key": "GMM",
            "comment": "Modelo probabilístico que assume que os dados são gerados por uma mistura de distribuições gaussianas."
          },
          {
            "name": "Hierarchical Clustering",
            "key": "HIER_CLUST",
            "comment": "Cria uma hierarquia de clusters através de abordagens aglomerativas (bottom-up) ou divisivas (top-down)."
          },
          {
            "name": "K-Means",
            "key": "KMEANS",
            "comment": "Algoritmo de particionamento que divide dados em k clusters, minimizando a variância intra-cluster."
          }
        ]
      },
      {
        "name": "Regras de Associação",
        "key": "ASSOC",
        "comment": "Algoritmos que descobrem relações frequentes entre itens, identificando padrões de co-ocorrência em conjuntos de dados.",
        "subtopics": [
          {
            "name": "Apriori",
            "key": "APRIORI",
            "comment": "Algoritmo clássico para mineração de regras de associação, usando a propriedade de antimonotonicidade para reduzir o espaço de busca."
          },
          {
            "name": "Eclat",
            "key": "ECLAT",
            "comment": "Equivalence Class Clustering and bottom-up Lattice Traversal - Algoritmo eficiente que usa representação vertical para mineração de itens frequentes."
          },
          {
            "name": "FP-Growth",
            "key": "FP_GROWTH",
            "comment": "Frequent Pattern Growth - Usa estrutura FP-tree compacta para mineração eficiente de padrões frequentes sem gerar candidatos."
          }
        ]
      },
      {
        "name": "Redução de Dimensionalidade",
        "key": "DIM_RED",
        "comment": "Técnicas que reduzem o número de características mantendo informações relevantes, facilitando visualização e processamento.",
        "subtopics": [
          {
            "name": "PCA",
            "key": "PCA",
            "comment": "Principal Component Analysis - Técnica linear que transforma dados em componentes principais ortogonais de maior variância."
          },
          {
            "name": "t-SNE",
            "key": "TSNE",
            "comment": "t-Distributed Stochastic Neighbor Embedding - Técnica não-linear para visualização que preserva distâncias locais em espaços de alta dimensão."
          }
        ]
      },
      {
        "name": "Redução de Dimensionalidade/Extração de Características",
        "key": "DIM_RED_FEAT",
        "comment": "Técnicas que simultaneamente reduzem dimensionalidade e extraem características relevantes dos dados originais.",
        "subtopics": [
          {
            "name": "Autoencoders",
            "key": "AUTOENCODERS",
            "comment": "Redes neurais não supervisionadas que aprendem representações comprimidas (codificadores) e reconstroem os dados (decodificadores)."
          }
        ]
      }
    ]
  }
}
